{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCH2p9ONxEQ92wpQKCpK+w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mudathir-Salahudeen/HEFA-PIPELINE/blob/main/ISS_HEFA_CODE_MAY_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "\n",
        "!pip install azure-storage-blob\n",
        "!pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tBuf1zsRXYt",
        "outputId": "8806b341-c842-4473-bbe9-b7b09ee50751"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.20.0-py3-none-any.whl (392 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.2/392.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core>=1.28.0 (from azure-storage-blob)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (42.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.11.0)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.28.0->azure-storage-blob) (2.31.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.28.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-blob) (2024.2.2)\n",
            "Installing collected packages: isodate, azure-core, azure-storage-blob\n",
            "Successfully installed azure-core-1.30.1 azure-storage-blob-12.20.0 isodate-0.6.1\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUcgkYkmOKP2",
        "outputId": "11d6f209-5e70-4f06-9200-8f841af9f044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformation and upload complete.\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "Output v4-Finalized Orignial/ISS Pipelines/Input/PHC_APR_2024.csv\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n",
            "File exists and has been appended\n"
          ]
        }
      ],
      "source": [
        "# Azure Libraries\n",
        "from azure.storage.blob import BlobClient\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.storage.blob import ContainerClient\n",
        "\n",
        "# Data Maniulation Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "from io import StringIO\n",
        "import openpyxl\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set up the Azure Storage Account credentials\n",
        "connectionString = \"DefaultEndpointsProtocol=https;AccountName=kdbstorage123;AccountKey=gwEZVLk9QqhfW/pjLKd7nzziYyDRD8nu8SDGKYkyWpJBk+QeJxHFTrOW97LD+UIMRJYR5mP787Vc8r0CF3XDFQ==;EndpointSuffix=core.windows.net\"\n",
        "# Set up the Blob Service\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connectionString)\n",
        "#Set Container name\n",
        "container_name = 'hefaanalytics'\n",
        "#Create Container Object\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "container_name = 'hefaanalytics'\n",
        "\n",
        "\n",
        "# Pick the latest file in the input folder (Bolajis latest uploaded file)\n",
        "raw_data_filepath = 'Output v4-Finalized Orignial/ISS Pipelines/Input/RawData'\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blob_list = container_client.list_blobs(name_starts_with=raw_data_filepath)\n",
        "# Sort the blob list by last modified time\n",
        "sorted_blob_list = sorted(blob_list, key=lambda x: x.last_modified, reverse=True)\n",
        "# Get the latest blob\n",
        "latest_blob = blob_service_client.get_blob_client(container=container_name, blob=sorted_blob_list[0].name)\n",
        "# Download the blob content as a string\n",
        "blob_content = latest_blob.download_blob().content_as_text()\n",
        "# Create a pandas DataFrame from the string data\n",
        "df = pd.read_csv(StringIO(blob_content))\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "# df = read_file(df) #reads the file into a dataframe using the read_file function.\n",
        "# factl_namecol = facility_namcol()\n",
        "# merged_df = group_slice(df, factl_namecol[0])   #merges the teamlead and nonteamlead dataframe back into one after grouping and slicing out the relevant columns for each.\n",
        "#merged_df.head()\n",
        "\n",
        "#merged_df.to_csv('bolaji1.csv',index=False)\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "# Convert the transformed DataFrame back to a CSV file as bytes\n",
        "# transformed_csv_bytes = merged_df.to_csv(index=False).encode()\n",
        "transformed_csv_bytes = df.to_csv(index=False).encode()\n",
        "\n",
        "output_container_name = 'hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Input'\n",
        "# Get a BlobClient object for the output CSV file\n",
        "csv_filename = sorted_blob_list[0].name.split(\"/\")[-1]\n",
        "output_blob_client = blob_service_client.get_blob_client(container=output_container_name, blob=csv_filename)\n",
        "\n",
        "# Upload the transformed CSV file to the output container\n",
        "output_blob_client.upload_blob(transformed_csv_bytes, overwrite=True)\n",
        "\n",
        "print(\"Transformation and upload complete.\")\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "def ISS_Transformation():\n",
        "\n",
        "    PHC_SERVICES = ['id',\n",
        "    'nutrition_mm13-patient_management_mm13-nutrition_counselling_mm13',\n",
        "    'pregnancy_mm4-service_provision_mm4-Focused_ANC_mm4',\n",
        "    'pregnancy_mm4-service_provision_mm4-ganc_mm4',\n",
        "    'chilhbirth_mm5-serviceprovision_mm5-Prevention_of_Mother_to_Child_Transmission_of_HIV_mm5',\n",
        "    'Tuberculosis_dot_mm9-service_provision_mm9-Directly_Observed_Treatment_Short_course_mm9',\n",
        "    'chilhbirth_mm5-serviceprovision_mm5-Care_during_labour_and_childbirth_mm5',\n",
        "    'adolescence_prepregnancy-serviceprovision_mm3-Family_Planning_mm3',\n",
        "    'postpartum_mm6-service_provision_mm6-Counselling_and_provision_of_family_planning_services_mm6',\n",
        "    'pregnancy_mm4-service_provision_mm4-Identification_and_referral_of_pregnant_women_with_complications_mm4',\n",
        "    'pregnancy_mm4-service_provision_mm4-Referral_of_PW_to_Community_Volunteer',\n",
        "    'chilhbirth_mm5-serviceprovision_mm5-Detection_and_referral_of_patients_with_complication_mm5',\n",
        "    'postpartum_mm6-service_provision_mm6-Referral_of_mother_with_complication_mm6',\n",
        "    'newborn_care_mm7-service_provision_mm7-Referral_mm7',\n",
        "    'childhealth_mm8-service_provision_mm8-Identification_and_Referral_of_Children_with_danger_signs_mm8',\n",
        "    'HIV_prevention_and_treatment_mm10-service_provision-referral_service_mm10',\n",
        "    'malariamanagement_control-service_provision_mm11-referrals_mm11',\n",
        "    'immunization_mm12-rew_micrplan_in_use_mm12',\n",
        "    'childhealth_mm8-service_provision_mm8-Integrated_Management_of_Childhood_Illness_mm8',\n",
        "    'chilhbirth_mm5-serviceprovision_mm5-Prevention_of_Mother_to_Child_Transmission_of_HIV_mm5',\n",
        "   'immunization_offered'\n",
        "     ]\n",
        "\n",
        "    SHF_SERVICES = ['id',\n",
        "    'ggrp8-hiv_preventn_treatmnt-adolescent_friendly_and_youth_wellness_services-adst-do_clients_receive_hts',\n",
        "    'ggrp8-hiv_preventn_treatmnt-hiv_service-hivser-is_counselling_and_testing_provided_on_the_same_day_at_the_one_stop_shop',\n",
        "    'ggrp2-pregnancy-service_provision_b-zzz2-provide_antenatal_care_services',\n",
        "    'ggrp2-pregnancy-service_provision_b-zzz2-provide_general_antenatal_care_services',\n",
        "    'ggrp8-hiv_preventn_treatmnt-adolescent_friendly_and_youth_wellness_services-group153-do_clients_receive_sexually_transmitted_infection_screening',\n",
        "    'ggrp6-childhealth-service_provision_f-group109-q4_provide_comprehensive_care_for_children_infected_with_or_exposed_to_hiv',\n",
        "    'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-do_hiv_infected_children_with_unsuppressed_viral_load_undergo_eac',\n",
        "    'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art',\n",
        "    'ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care',\n",
        "    'ggrp3-childbirth_labour-service_provision_c-zzz37-provide_care_during_labour_and_delivery',\n",
        "    'ggrp3-childbirth_labour-service_provision_c-zzz37-manage_obstetric_complications_in_childbirth_and_immediate_post_partum_period',\n",
        "    'ggrp8-hiv_preventn_treatmnt-treatment_support-group157-family_planning_counseling',\n",
        "    'ggrp4-postpartum-service_provision_d-group93-provide_referral_services',\n",
        "    'ggrp5-newborn_care-service_provision_newborn_care_e-group99-offer_referral_services',\n",
        "    'ggrp2-pregnancy-service_provision_b-zzz2-nutritional_counselling_and_food_demonstration',\n",
        "    'ggrp10-immunization-service_provision_h-group214-followup_planned_routine_immunization_session_being_conducted',\n",
        "    'ggrp6-childhealth-service_provision_f-zzz159-manage_common_childhood_illnesses',\n",
        "    'ggrp6-childhealth-service_provision_f-zzz159-manage_children_with_severe_illness',\n",
        "    'ggrp6-childhealth-service_provision_f-group110-provide_integrated_management_of_childhood_illness',\n",
        "    'ggrp4-postpartum-service_provision_d-group93-do_screening_and_initiation_or_continuation_of_arv',\n",
        "    'ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-group165-are_all_heis_provided_with_arv_prophylaxis_at_birth',\n",
        "    'ggrp3-childbirth_labour-service_provision_c-group79-carry_out_initiation_or_continuation_of_hiv_therapy',\n",
        "    'ggrp3-childbirth_labour-service_provision_c-group79-perform_emergency_caesarean_sections',\n",
        "    'ggrp4-postpartum-service_provision_d-zzz86-do_counseling_and_provide_family_planning_services_contraceptive_implants',\n",
        "    'ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_prevention_and_management_of_hiv_sexually_transmitted_infection',\n",
        "    'ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_appropriate_management_of_infertile_couple_including_hiv_discordant_couples',\n",
        "    'ggrp6-childhealth-service_provision_f-group109-q4_provide_comprehensive_care_for_children_infected_with_or_exposed_to_hiv',\n",
        "    'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-do_hiv_infected_children_with_unsuppressed_viral_load_undergo_eac',\n",
        "    'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art',\n",
        "    'ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care']\n",
        "\n",
        "\n",
        "    PHC_EQUIPMENT = ['id',\n",
        "    'chilhbirth_mm5-equipment_mm5-delivery_bed_mm5',\n",
        "    'pregnancy_mm4-equipment_mm4-Digital_Blood_Pressure_Device_mm4',\n",
        "    'Tuberculosis_dot_mm9-service_provision_mm9-microscopes_mm9',\n",
        "    'chilhbirth_mm5-equipment_mm5-Oxygen_mm5',\n",
        "    'chilhbirth_mm5-equipment_mm5-Ambu_bag_mask_mm5',\n",
        "    'pregnancy_mm4-equipment_mm4-Sphygmanometer_mm4',\n",
        "    'chilhbirth_mm5-equipment_mm5-Sphygmomanometer_and_Stethoscope_mm5',\n",
        "    'pregnancy_mm4-equipment_mm4-Fetal_and_Adult_Stethoscope_mm4',\n",
        "    'chilhbirth_mm5-equipment_mm5-Adult_Stethoscope_and_Fetoscope_mm5',\n",
        "    'chilhbirth_mm5-equipment_mm5-thermometer_mm5',\n",
        "    'newborn_care_mm7-equipment_mm7-Low_reading_thermomether_mm7',\n",
        "    'pregnancy_mm4-equipment_mm4-Weighing_Scale_mm4',\n",
        "    'childhealth_mm8-equipment_mm8-Infant_Weighing_Scales_mm8',\n",
        "    'nutrition_mm13-equipment_mm13-weighing_scale_mm13',\n",
        "    'nutrition_mm13-equipment_mm13-weighing_scale_adult_mm13',\n",
        "    'Tuberculosis_dot_mm9-service_provision_mm9-microscopes_mm9',\n",
        "    'laboratoryServices-m102-bleachAndDisinfectants',\n",
        "    'chilhbirth_mm5-equipment_mm5-syringes_mm5',\n",
        "    'newborn_care_mm7-equipment_mm7-Bulb_syringe_mm7',\n",
        "    'newborn_care_mm7-equipment_mm7-syringes2ml_mm7',\n",
        "    'childhealth_mm8-equipment_mm8-Cold_chain_equipments_Fridge_mm8']\n",
        "\n",
        "\n",
        "    SHF_EQUIPMENT = ['id',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-zzz55-delivery_packs',\n",
        "    'ggrp5-newborn_care-equipment_and_supplies_e-group105-facility_have_incubators',\n",
        "    'ggrp2-pregnancy-equipment_and_supplies_b-zzz20-digital_blood_pressure_device_traffic_light_',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-group87-iv_giving_sets',\n",
        "    'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-group67-a_theatre_for_surgical_procedure',\n",
        "    'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-group68-is_oxygen_available',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-group83-oxygen',\n",
        "    'ggrp2-pregnancy-equipment_and_supplies_b-group75-sphygmomanometer',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-zzz55-sphygmomanometer',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-group84-adult_stethoscopes_and_fetoscopes',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-group85-clinical_thermometers',\n",
        "    'ggrp5-newborn_care-equipment_and_supplies_e-zzz133-facility_have_thermometers',\n",
        "    'ggrp2-pregnancy-equipment_and_supplies_b-zzz20-weighing_scale',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-group85-weighing_scales',\n",
        "    'ggrp5-newborn_care-equipment_and_supplies_e-group106-facility_have_weighing_scales',\n",
        "    'ggrp6-childhealth-equipment_and_supplies_f-sss23-facility_have_weighing_scales_and_heightometers',\n",
        "    'ggrp11-nutrition-equipment_and_supplies_i-group237-weighing_scales__for_infants_and_adults_',\n",
        "    'ggrp16-laboratoryServices-facility_safety-group260-bleach_and_other_disinfectants',\n",
        "    'ggrp3-childbirth_labour-equipment_and_supplies_c-group86-gloves_syringes_and_needles']\n",
        "\n",
        "\n",
        "    # PHC_INFRASTRUCTURE = ['id',\n",
        "    # 'grp1-ExternalEnvironmentPhysicalInfrastructure-functional_source_of_power_supply_to_this_facility',\n",
        "    # 'grp1-ExternalEnvironmentPhysicalInfrastructure-health_facility_fenced']\n",
        "\n",
        "    PHC_INFRASTRUCTURE = ['id','grp1-ExternalEnvironmentPhysicalInfrastructure-Accessible_road_to_the_facility',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-environment_generally_tidy',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-walls_free_of_cracks',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-roof_intact_with_no_leaking',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-facility_well_ventilated',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-potable_water_available',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-sewage_disposal_system_adequate',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-waste_disposal_system_adequate',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-sharp_disposal_system',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-quaterly_rodent_and_pest_control',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-functional_source_of_power_supply_to_this_facility',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-separate_toilet_facilities_for_males_and_females',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-health_facility_fenced',\n",
        "    'grp1-ExternalEnvironmentPhysicalInfrastructure-facility_space_adequate_for_different_intervention',\n",
        "    ]\n",
        "\n",
        "\n",
        "    # SHF_INFRASTRUCTURE = ['id',\n",
        "    # 'grp1-external_env_and_infrastructure-group8-functional_source_of_power_supply_to_the_facility',\n",
        "    # 'grp1-external_env_and_infrastructure-group8-facility_fenced']\n",
        "\n",
        "    SHF_INFRASTRUCTURE = ['id',\n",
        "    'grp1-external_env_and_infrastructure-ff17-accessible_road_to_the_facility',\n",
        "       'grp1-external_env_and_infrastructure-ff17-facility_environment_generally_neat_and_tidy',\n",
        "       'grp1-external_env_and_infrastructure-ff17-walls_free_of_cracks_and_crevices',\n",
        "       'grp1-external_env_and_infrastructure-group5-roof_intact_with_no_leaking_part',\n",
        "       'grp1-external_env_and_infrastructure-group5-facility_well_ventilated',\n",
        "       'grp1-external_env_and_infrastructure-group5-facility_have_potable_water',\n",
        "       'grp1-external_env_and_infrastructure-group6-facilitys_sewage_disposal_system_adequate',\n",
        "       'grp1-external_env_and_infrastructure-group6-facilitys_waste_disposal_system_adequate',\n",
        "       'grp1-external_env_and_infrastructure-group6-facility_have_a_sharp_disposal_system_in_place',\n",
        "       'grp1-external_env_and_infrastructure-group7-facility_have_a_colour_coded_bin',\n",
        "       'grp1-external_env_and_infrastructure-group7-facility_carry_out_quarterly_pest_control_activities',\n",
        "       'grp1-external_env_and_infrastructure-group7-incinerator_in_the_facility',\n",
        "       'grp1-external_env_and_infrastructure-group8-functional_source_of_power_supply_to_the_facility',\n",
        "       'grp1-external_env_and_infrastructure-group8-facility_fenced',\n",
        "       'grp1-external_env_and_infrastructure-group8-neonatal_intensive_care_unit_3_or_special_care_baby_unit_2_',\n",
        "       'grp1-external_env_and_infrastructure-group9-facility_have_a_functional_and_well_equipped_ambulance',\n",
        "       'grp1-external_env_and_infrastructure-group9-facilty_have_a_referral_directory',\n",
        "       'grp1-external_env_and_infrastructure-group10-mobile_phone_network_available_at_the_facilty']\n",
        "\n",
        "\n",
        "    PHC_STAFF_AVAILABILITY = ['id',\n",
        "    'grp1-humanResources-staffAvailability-no_registered_midwives_nurses',\n",
        "    'grp1-humanResources-staffAvailability-no_jchew',\n",
        "    'grp1-humanResources-staffAvailability-no_labtech',\n",
        "    'grp1-humanResources-staffAvailability-no_pharmtech',\n",
        "    'grp1-humanResources-staffAvailability-no_chew',\n",
        "    'grp1-humanResources-staffAvailability-no_CHO',\n",
        "    'grp1-humanResources-staffAvailability-no_medical_officers',\n",
        "    'grp1-humanResources-staffAvailability-num_Community_Volunteers_are_available']\n",
        "\n",
        "\n",
        "    SHF_STAFF_AVAILABILITY = ['id',\n",
        "    'grp1-human_resources-staff_availability-group32-followup_how_many_registered_midwives',\n",
        "    'grp1-human_resources-staff_availability-group33-followup_how_many_registered_general_nurses',\n",
        "    'grp1-human_resources-staff_availability-group36-followup_how_many_laboratory_technicians',\n",
        "    'grp1-human_resources-staff_availability-group35-followup_how_many_pharmacy_technicians',\n",
        "    'grp1-human_resources-staff_availability-group39-followup_how_many_community_health_officers',\n",
        "    'grp1-human_resources-staff_availability-group31-followup_how_many_medical_officers']\n",
        "\n",
        "\n",
        "    PHC_STAFF_TRAINING = ['id',\n",
        "    'grp1-humanResources-staffTraining-num_trained_malaria',\n",
        "    'grp1-humanResources-staffTraining-num_trained_youthfriendly_centre',\n",
        "    'grp1-humanResources-staffTraining-num_trained_famplanning',\n",
        "    'grp1-humanResources-staffTraining-num_trained_HIV',\n",
        "    'grp1-humanResources-staffTraining-num_trained_imci',\n",
        "    'grp1-humanResources-staffTraining-num_trained_hmis_tool']\n",
        "\n",
        "\n",
        "    SHF_STAFF_TRAINING = ['id',\n",
        "    'grp1-human_resources-staff_training-group57-staff_trained_on_malaria_management',\n",
        "    'grp1-human_resources-staff_training-group53-staff_trained_on_youth_friendly_health_services',\n",
        "    'grp1-human_resources-staff_training-group52-staff_trained_on_fp_clms_and_ctu_',\n",
        "    'grp1-human_resources-staff_training-group50-staff_trained_on_hiv_aids_management',\n",
        "    'grp1-human_resources-staff_training-group52-staff_trained_on_hts',\n",
        "    'grp1-human_resources-staff_training-group49-staff_trained_on_integrated_management_of_childhood_illness',\n",
        "    'grp1-human_resources-staff_training-group54-staff_trained_on_using_nhmis_version_19_tools']\n",
        "\n",
        "\n",
        "    PHC_LOGISTICS = ['id',\n",
        "    'logisticsManagement-albendazole',\n",
        "    'logisticsManagement-mebendazole',\n",
        "    'logisticsManagement-acts',\n",
        "    'logisticsManagement-amitriptyline',\n",
        "    'logisticsManagement-dispersible',\n",
        "    'logisticsManagement-contraceptive',\n",
        "    'logisticsManagement-diazepam',\n",
        "    'logisticsManagement-folic',\n",
        "    'logisticsManagement-condomMale',\n",
        "    'logisticsManagement-condomFemale',\n",
        "    'logisticsManagement-vitaminA',\n",
        "    'logisticsManagement-tetanus',\n",
        "    'logisticsManagement-zincORS',\n",
        "    'logisticsManagement-coldChainItems']\n",
        "\n",
        "\n",
        "    SHF_LOGISTICS = ['id',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group345-albendazole',\n",
        "    'ggrp11-nutrition-medicines_and_other_health_technologies_i-group239-albendezole_mebendazole',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group344-act',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group345-dispersible_amoxicillin_tablets',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group348-oral_pills',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group339-iron_and_folic_acid_tablet',\n",
        "    'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-ff230-are_male_condoms_available',\n",
        "    'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-ff230-are_female_condoms_available',\n",
        "    'ggrp6-childhealth-medicines_and_other_health_technologies_f-group120-facility_have_vitamin_a',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group341-tetanus_toxoid',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group346-zinc_tablet',\n",
        "    'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group346-oxytocine']\n",
        "\n",
        "    #4 create a list for all the PHC intervention column name lists\n",
        "    ALL_PHC = [PHC_EQUIPMENT,PHC_INFRASTRUCTURE,PHC_LOGISTICS, PHC_SERVICES, PHC_STAFF_AVAILABILITY, PHC_STAFF_TRAINING]\n",
        "\n",
        "    #5 create a list for all the SHF intervention column name lists\n",
        "    ALL_SHF = [SHF_EQUIPMENT, SHF_INFRASTRUCTURE, SHF_LOGISTICS, SHF_SERVICES, SHF_STAFF_AVAILABILITY, SHF_STAFF_TRAINING]\n",
        "\n",
        "    #6 create a list of strings for all intervention names\n",
        "    PHC_interv = [\"PHC EQUIPMENT\", \"PHC INFRASTRUCTURE\", \"PHC LOGISTICS\", \"PHC SERVICES\", \"PHC STAFF AVAILABILITY\", \"PHC STAFF TRAINING\"]\n",
        "    SHF_interv = [\"SHF EQUIPMENT\", \"SHF INFRASTRUCTURE\", \"SHF LOGISTICS\", \"SHF SERVICES\", \"SHF STAFF AVAILABILITY\", \"SHF STAFF TRAINING\"]\n",
        "\n",
        "\n",
        "\n",
        "#     Pick the latest file in the input folder (Bolajis latest uploaded file) from Azure Storage\n",
        "    raw_data_filepath = 'Output v4-Finalized Orignial/ISS Pipelines/Input'\n",
        "    container_client = blob_service_client.get_container_client(container_name)\n",
        "    blob_list = container_client.list_blobs(name_starts_with=raw_data_filepath)\n",
        "    # Sort the blob list by last modified time\n",
        "    sorted_blob_list = sorted(blob_list, key=lambda x: x.last_modified, reverse=True)\n",
        "    # Get the latest blob\n",
        "    latest_blob = blob_service_client.get_blob_client(container=container_name, blob=sorted_blob_list[0].name)\n",
        "    # Download the blob content as a string\n",
        "    blob_content = latest_blob.download_blob().content_as_text()\n",
        "    # Create a pandas DataFrame from the string data\n",
        "    df = pd.read_csv(StringIO(blob_content))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    INFRA = df\n",
        "    # INFRA = pd.read_csv(path) #For local Testing\n",
        "\n",
        "    #19 rename an immunization column in the services dataset\n",
        "    if 'immunization_mm12-services_mm12-rew_micrplan_in_use_mm12' in INFRA.columns:\n",
        "        INFRA.rename({'immunization_mm12-services_mm12-rew_micrplan_in_use_mm12': 'immunization_mm12-rew_micrplan_in_use_mm12'},\n",
        "                    axis =1, inplace = True)\n",
        "\n",
        "    #20 renaming multiple columns in the interventions to avoid column mismatch while appending\n",
        "    # for phc equipment\n",
        "    equip=['id',\n",
        "       'chilhbirth_mm5-equipment_mm5-delivery_bed_mm5',\n",
        "       'pregnancy_mm4-equipment_mm4-Digital_Blood_Pressure_Device_mm4',\n",
        "       'Tuberculosis_dot_mm9-service_provision_mm9-microscopes_mm9',\n",
        "       'chilhbirth_mm5-equipment_mm5-Oxygen_mm5',\n",
        "       'chilhbirth_mm5-equipment_mm5-Ambu_bag_mask_mm5',\n",
        "       'pregnancy_mm4-equipment_mm4-Sphygmanometer_mm4',\n",
        "       'chilhbirth_mm5-equipment_mm5-Sphygmomanometer_and_Stethoscope_mm5',\n",
        "       'pregnancy_mm4-equipment_mm4-Fetal_and_Adult_Stethoscope_mm4',\n",
        "       'chilhbirth_mm5-equipment_mm5-Adult_Stethoscope_and_Fetoscope_mm5',\n",
        "       'chilhbirth_mm5-equipment_mm5-thermometer_mm5',\n",
        "       'newborn_care_mm7-equipment_mm7-Low_reading_thermomether_mm7',\n",
        "       'pregnancy_mm4-equipment_mm4-Weighing_Scale_mm4',\n",
        "       'childhealth_mm8-equipment_mm8-Infant_Weighing_Scales_mm8',\n",
        "       'nutrition_mm13-equipment_mm13-weighing_scale_mm13',\n",
        "       'nutrition_mm13-equipment_mm13-weighing_scale_adult_mm13',\n",
        "       'Tuberculosis_dot_mm9-service_provision_mm9-microscopes_mm9.1',\n",
        "       'laboratoryServices-m102-bleachAndDisinfectants',\n",
        "       'chilhbirth_mm5-equipment_mm5-syringes_mm5',\n",
        "       'newborn_care_mm7-equipment_mm7-Bulb_syringe_mm7',\n",
        "       'newborn_care_mm7-equipment_mm7-syringes2ml_mm7',\n",
        "        'childhealth_mm8-equipment_mm8-Cold_chain_equipments_Fridge_mm8','year',\n",
        "       'source']\n",
        "\n",
        "    #21 for phc services\n",
        "    serv =['id',\n",
        "       'nutrition_mm13-patient_management_mm13-nutrition_counselling_mm13',\n",
        "       'pregnancy_mm4-service_provision_mm4-Focused_ANC_mm4',\n",
        "       'pregnancy_mm4-service_provision_mm4-ganc_mm4',\n",
        "       'chilhbirth_mm5-serviceprovision_mm5-Prevention_of_Mother_to_Child_Transmission_of_HIV_mm5',\n",
        "       'Tuberculosis_dot_mm9-service_provision_mm9-Directly_Observed_Treatment_Short_course_mm9',\n",
        "       'chilhbirth_mm5-serviceprovision_mm5-Care_during_labour_and_childbirth_mm5',\n",
        "       'adolescence_prepregnancy-serviceprovision_mm3-Family_Planning_mm3',\n",
        "       'postpartum_mm6-service_provision_mm6-Counselling_and_provision_of_family_planning_services_mm6',\n",
        "       'pregnancy_mm4-service_provision_mm4-Identification_and_referral_of_pregnant_women_with_complications_mm4',\n",
        "       'pregnancy_mm4-service_provision_mm4-Referral_of_PW_to_Community_Volunteer',\n",
        "       'chilhbirth_mm5-serviceprovision_mm5-Detection_and_referral_of_patients_with_complication_mm5',\n",
        "       'postpartum_mm6-service_provision_mm6-Referral_of_mother_with_complication_mm6',\n",
        "       'newborn_care_mm7-service_provision_mm7-Referral_mm7',\n",
        "       'childhealth_mm8-service_provision_mm8-Identification_and_Referral_of_Children_with_danger_signs_mm8',\n",
        "       'HIV_prevention_and_treatment_mm10-service_provision-referral_service_mm10',\n",
        "       'malariamanagement_control-service_provision_mm11-referrals_mm11',\n",
        "       'immunization_mm12-rew_micrplan_in_use_mm12',\n",
        "       'childhealth_mm8-service_provision_mm8-Integrated_Management_of_Childhood_Illness_mm8',\n",
        "       'chilhbirth_mm5-serviceprovision_mm5-Prevention_of_Mother_to_Child_Transmission_of_HIV_mm5.1',\n",
        "        'immunization_offered',\n",
        "        'year', 'source']\n",
        "\n",
        "    #22 for shf services\n",
        "    shf_serv = ['id',\n",
        "       'ggrp8-hiv_preventn_treatmnt-adolescent_friendly_and_youth_wellness_services-adst-do_clients_receive_hts',\n",
        "       'ggrp8-hiv_preventn_treatmnt-hiv_service-hivser-is_counselling_and_testing_provided_on_the_same_day_at_the_one_stop_shop',\n",
        "       'ggrp2-pregnancy-service_provision_b-zzz2-provide_antenatal_care_services',\n",
        "       'ggrp2-pregnancy-service_provision_b-zzz2-provide_general_antenatal_care_services',\n",
        "       'ggrp8-hiv_preventn_treatmnt-adolescent_friendly_and_youth_wellness_services-group153-do_clients_receive_sexually_transmitted_infection_screening',\n",
        "       'ggrp6-childhealth-service_provision_f-group109-q4_provide_comprehensive_care_for_children_infected_with_or_exposed_to_hiv',\n",
        "       'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-do_hiv_infected_children_with_unsuppressed_viral_load_undergo_eac',\n",
        "       'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art',\n",
        "       'ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care',\n",
        "       'ggrp3-childbirth_labour-service_provision_c-zzz37-provide_care_during_labour_and_delivery',\n",
        "       'ggrp3-childbirth_labour-service_provision_c-zzz37-manage_obstetric_complications_in_childbirth_and_immediate_post_partum_period',\n",
        "       'ggrp8-hiv_preventn_treatmnt-treatment_support-group157-family_planning_counseling',\n",
        "       'ggrp4-postpartum-service_provision_d-group93-provide_referral_services',\n",
        "       'ggrp5-newborn_care-service_provision_newborn_care_e-group99-offer_referral_services',\n",
        "       'ggrp2-pregnancy-service_provision_b-zzz2-nutritional_counselling_and_food_demonstration',\n",
        "       'ggrp10-immunization-service_provision_h-group214-followup_planned_routine_immunization_session_being_conducted',\n",
        "       'ggrp6-childhealth-service_provision_f-zzz159-manage_common_childhood_illnesses',\n",
        "       'ggrp6-childhealth-service_provision_f-zzz159-manage_children_with_severe_illness',\n",
        "       'ggrp6-childhealth-service_provision_f-group110-provide_integrated_management_of_childhood_illness',\n",
        "       'ggrp4-postpartum-service_provision_d-group93-do_screening_and_initiation_or_continuation_of_arv',\n",
        "       'ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-group165-are_all_heis_provided_with_arv_prophylaxis_at_birth',\n",
        "       'ggrp3-childbirth_labour-service_provision_c-group79-carry_out_initiation_or_continuation_of_hiv_therapy',\n",
        "       'ggrp3-childbirth_labour-service_provision_c-group79-perform_emergency_caesarean_sections',\n",
        "       'ggrp4-postpartum-service_provision_d-zzz86-do_counseling_and_provide_family_planning_services_contraceptive_implants',\n",
        "       'ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_prevention_and_management_of_hiv_sexually_transmitted_infection',\n",
        "       'ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_appropriate_management_of_infertile_couple_including_hiv_discordant_couples',\n",
        "       'ggrp6-childhealth-service_provision_f-group109-q4_provide_comprehensive_care_for_children_infected_with_or_exposed_to_hiv.1',\n",
        "       'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-do_hiv_infected_children_with_unsuppressed_viral_load_undergo_eac.1',\n",
        "       'ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art.1',\n",
        "       'ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care.1',\n",
        "       'year','source']\n",
        "\n",
        "    # latest Input Filename\n",
        "    path = sorted_blob_list[0].name\n",
        "#     path = 'Local Path'   #For local Testing\n",
        "\n",
        "    #23 operations to be executed if 'file' selected is 1 (1 for PHC)\n",
        "    if 'PHC' in path:\n",
        "\n",
        "        #24 Iterate through each intervention for the number intervention times\n",
        "        for j in range(len(PHC_interv)):\n",
        "\n",
        "            #25 operations to be done for staff training (index is 5)\n",
        "            if j == 5:\n",
        "                #26 create a dataframe of intervention at index 5\n",
        "                df = pd.DataFrame(INFRA[ALL_PHC[j]])\n",
        "\n",
        "                #27 recode values greater than 1 to 'Yes' in this particular column\n",
        "                df['grp1-humanResources-staffTraining-num_trained_imci']= df['grp1-humanResources-staffTraining-num_trained_imci'].apply(lambda x: 'Yes' if x >= 1 else 'No')\n",
        "\n",
        "                # recode 1 to 'Yes' and 0 to 'No', missing values to 'N_A'\n",
        "                # Remove the 'id' column temporarily so that the ids will not be affected whn the replacement happens\n",
        "                df_without_id = df.drop(columns=['id'])\n",
        "                # Perform the transformation\n",
        "                df_without_id.replace({1: 'Yes', 0: 'No',  np.nan: 'N/A'}, inplace=True)\n",
        "                # Add the 'id' column back\n",
        "                df = pd.concat([df['id'], df_without_id], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "                #29  extracting the year and source from the file path/source by counting the number of underscores(_) in the path name\n",
        "                # and assign them to new columns 'year' and 'source'\n",
        "                # if path.count('_') == 4:\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "\n",
        "                # elif path.count('_') == 5:\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "            if j != 4 and j != 5:#30 operations to be performed for all interventions except 4(PHC Staff availability) and 5(staff training)\n",
        "                df = pd.DataFrame(INFRA[ALL_PHC[j]]) #31 transform each intervention to dataframe and store as 'df' variable\n",
        "\n",
        "                # recode 1 to 'Yes' and 0 to 'No', missing values to 'N_A'\n",
        "                # Remove the 'id' column temporarily so that the ids will not be affected whn the replacement happens\n",
        "                df_without_id = df.drop(columns=['id'])\n",
        "                # Perform the transformation\n",
        "                df_without_id.replace({1: 'Yes', 0: 'No', 204: 'No', np.nan: 'N/A'}, inplace=True)\n",
        "                # Add the 'id' column back\n",
        "                df = pd.concat([df['id'], df_without_id], axis=1)\n",
        "\n",
        "                #32 extract the ISS year from the data source path and assign the year as a new column in the dataset\n",
        "                # by counting the number of underscore '_' in the path name\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "\n",
        "                # elif path.count('_') == 5:\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "                #34 rename phc equipment column names to already created column names. 0 == phc equipment\n",
        "                if j == 0:\n",
        "                    df.columns.values[:]=equip\n",
        "\n",
        "                #35 rename phc service column names to already created column names. 3 == phc services\n",
        "                if j == 3:\n",
        "                    df.columns.values[:]=serv\n",
        "\n",
        "#           #36 operations to be done for intervention with index 4 (staff availability)\n",
        "            if j == 4:\n",
        "                df = pd.DataFrame(INFRA[ALL_PHC[j]])\n",
        "                df.replace({\n",
        "                    np.nan:'N/A'},inplace =True)\n",
        "\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "\n",
        "                # elif path.count('_') == 5:\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "            name = f'{PHC_interv[j]}.xlsx'\n",
        "#             print(name)\n",
        "\n",
        "            # #38 for new output\n",
        "            # if name not in os.listdir('/content/sample_data/output/PHC'):\n",
        "            #     df.to_csv(f'/content/sample_data/output/PHC{PHC_interv[j]}.csv',index=False)\n",
        "            # #39 to append\n",
        "            # else:\n",
        "            #     df2=pd.read_csv(f'/content/sample_data/output/PHC{PHC_interv[j]}.csv')\n",
        "            #     df2=df2.append(df).to_csv(f'/content/sample_data/output/PHC{PHC_interv[j]}.csv',index=False)\n",
        "\n",
        "            PHC_out_filepath = 'hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/PHC'\n",
        "            blob_client = blob_service_client.get_blob_client(container=PHC_out_filepath, blob=name)\n",
        "\n",
        "\n",
        "\n",
        "            if not blob_client.exists():\n",
        "                # If the file doesn't exist, create a new one\n",
        "                dataframe_Buffer = io.BytesIO()\n",
        "                df.to_excel(dataframe_Buffer, index=False)\n",
        "                df_value = dataframe_Buffer.getvalue()\n",
        "                blob_client.upload_blob(df_value, overwrite=True)\n",
        "                print(\"File doesn't exist and has been uploaded\")\n",
        "            else:\n",
        "                # If the file exists, append the data to the existing file\n",
        "                stream = blob_client.download_blob().content_as_bytes()\n",
        "                df2 = pd.read_excel(io.BytesIO(stream))\n",
        "                df2 = df2.reset_index(drop=True)\n",
        "\n",
        "                # df2 = df2.append(df)\n",
        "                # df3 = df2.drop_duplicates(keep='first') # drop duplicates\n",
        "\n",
        "                # Use pd.concat instead of df.append\n",
        "                df3 = pd.concat([df2, df]).drop_duplicates(keep='first')\n",
        "\n",
        "                # Upload excel file\n",
        "                dataframe_Buffer = io.BytesIO()\n",
        "                df3.to_excel(dataframe_Buffer, index=False)\n",
        "                df3_value = dataframe_Buffer.getvalue()\n",
        "                blob_client.upload_blob(df3_value, overwrite=True)\n",
        "                print(\"File exists and has been appended\")\n",
        "\n",
        "        print(path)\n",
        "\n",
        "\n",
        "    #41 check if the initial input file option  is 2 (for SHF files)\n",
        "    elif 'SHF' in path:\n",
        "        for j in range(len(SHF_interv)):\n",
        "            if j != 4: #42 operations to be performed for all interventions expect staff availability (which is index 4)\n",
        "                df = pd.DataFrame(INFRA[ALL_SHF[j]])\n",
        "\n",
        "                # recode 1 to 'Yes' and 0 to 'No', missing values to 'N_A'\n",
        "                # Remove the 'id' column temporarily so that the ids will not be affected whn the replacement happens\n",
        "                df_without_id = df.drop(columns=['id'])\n",
        "                # Perform the transformation\n",
        "                df_without_id.replace({1: 'Yes', 0: 'No', np.nan: 'N/A'}, inplace=True)\n",
        "                # Add the 'id' column back\n",
        "                df = pd.concat([df['id'], df_without_id], axis=1)\n",
        "\n",
        "\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "\n",
        "                # elif path.count('_') == 5:\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "\n",
        "                if j == 3:\n",
        "                    df.columns.values[:]=shf_serv\n",
        "\n",
        "            #43 operations to be performed for staff availability intervention (index 4)\n",
        "            if j == 4:\n",
        "                df = pd.DataFrame(INFRA[ALL_SHF[j]])\n",
        "\n",
        "                df.replace({\n",
        "                    np.nan:'N/A'},inplace =True)\n",
        "\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "\n",
        "\n",
        "                # elif path.count('_') == 5:\n",
        "                year = path.split('/')[-1].split('.')[0].split('_')[-1]\n",
        "                df['year'] = year\n",
        "\n",
        "                source = path.split('/')[-1].split('.')[0]\n",
        "                df['source'] = source\n",
        "\n",
        "            name = f'{SHF_interv[j]}.xlsx'\n",
        "\n",
        "\n",
        "            # #38 for new output\n",
        "            # if name not in os.listdir('../output/SHF/'):\n",
        "            #     df.to_csv(f'../output/SHF/{SHF_interv[j]}.csv',index=False)\n",
        "            # #39 to append\n",
        "            # else:\n",
        "            #     df2=pd.read_csv(f'../output/SHF/{SHF_interv[j]}.csv')\n",
        "            #     df2=df2.append(df).to_csv(f'../output/SHF/{SHF_interv[j]}.csv',index=False)\n",
        "\n",
        "\n",
        "            SHF_out_filepath = 'hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/SHF'\n",
        "            blob_client = blob_service_client.get_blob_client(container=SHF_out_filepath, blob=name)\n",
        "\n",
        "            # FOR EXCEL FILES\n",
        "            if not blob_client.exists():\n",
        "                # If the file doesn't exist, create a new one\n",
        "                dataframe_Buffer = io.BytesIO()\n",
        "                df.to_excel(dataframe_Buffer, index=False)\n",
        "                df_value = dataframe_Buffer.getvalue()\n",
        "                blob_client.upload_blob(df_value, overwrite=True)\n",
        "                print(\"File doesn't exist and has been uploaded\")\n",
        "            else:\n",
        "                # If the file exists, append the data to the existing file\n",
        "                stream = blob_client.download_blob().content_as_bytes()\n",
        "                df2 = pd.read_excel(io.BytesIO(stream))\n",
        "                # df2 = df2.append(df)\n",
        "                # df3 = df2.drop_duplicates(keep='first') # drop duplicates\n",
        "\n",
        "                # Use pd.concat instead of df.append\n",
        "                df3 = pd.concat([df2, df]).drop_duplicates(keep='first')\n",
        "\n",
        "                # Upload excel file\n",
        "                dataframe_Buffer = io.BytesIO()\n",
        "                df3.to_excel(dataframe_Buffer, index=False)\n",
        "                df3_value = dataframe_Buffer.getvalue()\n",
        "                blob_client.upload_blob(df3_value, overwrite=True)\n",
        "                print(\"File exists and has been appended\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "ISS_Transformation()\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "# Function to upload the files as xlsx\n",
        "def upload_excel(dataframe, output_filepath, output_excel_filename):\n",
        "  blob_client = blob_service_client.get_blob_client(container=output_filepath, blob= output_excel_filename)\n",
        "  dataframe_Buffer = io.BytesIO()\n",
        "  dataframe.to_excel(dataframe_Buffer, index=False)\n",
        "  dataframe_value = dataframe_Buffer.getvalue()\n",
        "  blob_client.upload_blob(dataframe_value, overwrite=True)\n",
        "\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "\n",
        "#48 This entire function is designed to append all previous PHC and SHF outputs into 1 single unit file for each intervention\n",
        "def appending():\n",
        "\n",
        "\n",
        "    # PHC_fold = sorted(os.listdir('../output/PHC/'))\n",
        "    # SHF_fold = sorted(os.listdir('../output/SHF/'))\n",
        "\n",
        "    # List the blobs with .csv extension in the PHC folder\n",
        "    PHC_fold = sorted([blob.name for blob in blob_service_client.get_container_client(container_name).list_blobs(name_starts_with='Output v4-Finalized Orignial/ISS Pipelines/Output/PHC/') if blob.name.endswith('.xlsx')])\n",
        "    # List the blobs with .csv extension in the SHF folder\n",
        "    SHF_fold = sorted([blob.name for blob in blob_service_client.get_container_client(container_name).list_blobs(name_starts_with='Output v4-Finalized Orignial/ISS Pipelines/Output/SHF/') if blob.name.endswith('.xlsx')])\n",
        "\n",
        "\n",
        "    for i in range(len(PHC_fold)):\n",
        "        # phc_file = pd.read_csv(f\"../output/PHC/{PHC_fold[i]}\")\n",
        "        # shf_file = pd.read_csv(f\"../output/SHF/{SHF_fold[i]}\")\n",
        "\n",
        "        # Download the PHC Excel file from Azure Blob Storage\n",
        "        phc_blob_client = blob_service_client.get_blob_client(container_name, PHC_fold[i])\n",
        "        stream = phc_blob_client.download_blob().content_as_bytes()\n",
        "        phc_file = pd.read_excel(io.BytesIO(stream))\n",
        "\n",
        "        # Download the SHF file from Azure Blob Storage\n",
        "        shf_blob_client = blob_service_client.get_blob_client(container_name, SHF_fold[i])\n",
        "        stream = shf_blob_client.download_blob().content_as_bytes()\n",
        "        shf_file = pd.read_excel(io.BytesIO(stream))\n",
        "\n",
        "\n",
        "        #52 operations to be performed if the intervention input is 1\n",
        "        if 'EQUIPMENT' in PHC_fold[i] and 'EQUIPMENT' in SHF_fold[i]:\n",
        "\n",
        "            # 53 rename the mapped SHF column names to be uniform with the PHC column names\n",
        "            shf_file.rename({'ggrp3-childbirth_labour-equipment_and_supplies_c-zzz55-delivery_packs':'chilhbirth_mm5-equipment_mm5-delivery_bed_mm5',\n",
        "                    'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-group68-is_oxygen_available':'chilhbirth_mm5-equipment_mm5-Oxygen_mm5',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group83-oxygen':'chilhbirth_mm5-equipment_mm5-Ambu_bag_mask_mm5',\n",
        "                    'ggrp2-pregnancy-equipment_and_supplies_b-group75-sphygmomanometer':'pregnancy_mm4-equipment_mm4-Sphygmanometer_mm4',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-zzz55-sphygmomanometer':'chilhbirth_mm5-equipment_mm5-Sphygmomanometer_and_Stethoscope_mm5',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group84-adult_stethoscopes_and_fetoscopes':'pregnancy_mm4-equipment_mm4-Fetal_and_Adult_Stethoscope_mm4',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group85-clinical_thermometers':'chilhbirth_mm5-equipment_mm5-thermometer_mm5',\n",
        "                    'ggrp5-newborn_care-equipment_and_supplies_e-zzz133-facility_have_thermometers':'newborn_care_mm7-equipment_mm7-Low_reading_thermomether_mm7',\n",
        "                    'ggrp16-laboratoryServices-facility_safety-group260-bleach_and_other_disinfectants':'laboratoryServices-m102-bleachAndDisinfectants',\n",
        "                    'ggrp2-pregnancy-equipment_and_supplies_b-zzz20-digital_blood_pressure_device_traffic_light_':'pregnancy_mm4-equipment_mm4-Digital_Blood_Pressure_Device_mm4',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group85-weighing_scales':'childhealth_mm8-equipment_mm8-Infant_Weighing_Scales_mm8',\n",
        "                    'ggrp2-pregnancy-equipment_and_supplies_b-zzz20-weighing_scale':'pregnancy_mm4-equipment_mm4-Weighing_Scale_mm4'}, axis=1, inplace = True)\n",
        "\n",
        "\n",
        "            #54 concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file, shf_file], axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Equipment.csv')\n",
        "\n",
        "            equipment_df = pd.concat([phc_file, shf_file], axis=0, ignore_index=True)\n",
        "            equipment_df2 = equipment_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "            #reposition year and source\n",
        "            yr = equipment_df2.pop('year')\n",
        "            sc = equipment_df2.pop('source')\n",
        "            id = equipment_df2.pop('id')\n",
        "            equipment_df2=pd.concat([id,equipment_df2,yr,sc],axis=1)\n",
        "            # Upload df as xlsx to Azure\n",
        "            upload_excel(equipment_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/merged\", \"ISS_Equipment.xlsx\")\n",
        "\n",
        "        # operations to be performed if intervention input by the user is 2\n",
        "        elif 'INFRASTRUCTURE' in PHC_fold[i] and 'INFRASTRUCTURE' in SHF_fold[i]:\n",
        "            # rename all mapped SHF column names to be uniform with PHC column names\n",
        "            shf_file.rename({'grp1-external_env_and_infrastructure-group8-facility_fenced':'grp1-ExternalEnvironmentPhysicalInfrastructure-health_facility_fenced',\n",
        "\n",
        "            'grp1-external_env_and_infrastructure-ff17-accessible_road_to_the_facility':'grp1-ExternalEnvironmentPhysicalInfrastructure-Accessible_road_to_the_facility',\n",
        "            'grp1-external_env_and_infrastructure-group6-facilitys_sewage_disposal_system_adequate':'grp1-ExternalEnvironmentPhysicalInfrastructure-sewage_disposal_system_adequate',\n",
        "            'grp1-external_env_and_infrastructure-group5-facility_have_potable_water':'grp1-ExternalEnvironmentPhysicalInfrastructure-potable_water_available',\n",
        "            'grp1-external_env_and_infrastructure-group6-facility_have_a_sharp_disposal_system_in_place':'grp1-ExternalEnvironmentPhysicalInfrastructure-sharp_disposal_system',\n",
        "            'grp1-external_env_and_infrastructure-group5-facility_well_ventilated':'grp1-ExternalEnvironmentPhysicalInfrastructure-facility_well_ventilated',\n",
        "            'grp1-external_env_and_infrastructure-group5-roof_intact_with_no_leaking_part':'grp1-ExternalEnvironmentPhysicalInfrastructure-roof_intact_with_no_leaking',\n",
        "            'grp1-external_env_and_infrastructure-ff17-walls_free_of_cracks_and_crevices':'grp1-ExternalEnvironmentPhysicalInfrastructure-walls_free_of_cracks',\n",
        "            'grp1-external_env_and_infrastructure-group7-facility_carry_out_quarterly_pest_control_activities':'grp1-ExternalEnvironmentPhysicalInfrastructure-quaterly_rodent_and_pest_control',\n",
        "            'grp1-external_env_and_infrastructure-group8-functional_source_of_power_supply_to_the_facility':'grp1-ExternalEnvironmentPhysicalInfrastructure-functional_source_of_power_supply_to_this_facility',\n",
        "            'grp1-external_env_and_infrastructure-group6-facilitys_waste_disposal_system_adequate':'grp1-ExternalEnvironmentPhysicalInfrastructure-waste_disposal_system_adequate',\n",
        "            'grp1-external_env_and_infrastructure-ff17-facility_environment_generally_neat_and_tidy': 'grp1-ExternalEnvironmentPhysicalInfrastructure-environment_generally_tidy'\n",
        "            }, axis=1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file], axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Infrastructure.csv')\n",
        "\n",
        "            infra_df = pd.concat([phc_file,shf_file], axis=0, ignore_index=True)\n",
        "            infra_df2 = infra_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "\n",
        "            #reposition year and source\n",
        "            yr = infra_df2.pop('year')\n",
        "            sc = infra_df2.pop('source')\n",
        "            id = infra_df2.pop('id')\n",
        "            infra_df2=pd.concat([id,infra_df2,yr,sc],axis=1)\n",
        "\n",
        "            # Upload df as xlsx to Azure\n",
        "            upload_excel(infra_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/merged\", \"infrastructure_pipeline.xlsx\")\n",
        "\n",
        "        # operations to be performed if intervention input by the user is 3\n",
        "        elif 'LOGISTICS' in PHC_fold[i] and 'LOGISTICS' in SHF_fold[i]:\n",
        "            # rename all mapped SHF column names for the intervention to be uniform with that of the PHC column names\n",
        "            shf_file.rename({\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group345-albendazole':'logisticsManagement-albendazole',\n",
        "            'ggrp11-nutrition-medicines_and_other_health_technologies_i-group239-albendezole_mebendazole':'logisticsManagement-mebendazole',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group344-act':'logisticsManagement-acts',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group345-dispersible_amoxicillin_tablets':'logisticsManagement-dispersible',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group348-oral_pills':'logisticsManagement-contraceptive',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group339-iron_and_folic_acid_tablet':'logisticsManagement-folic',\n",
        "            'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-ff230-are_male_condoms_available':'logisticsManagement-condomMale',\n",
        "            'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-ff230-are_female_condoms_available':'logisticsManagement-condomFemale',\n",
        "            'ggrp6-childhealth-medicines_and_other_health_technologies_f-group120-facility_have_vitamin_a':'logisticsManagement-vitaminA',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group341-tetanus_toxoid':'logisticsManagement-tetanus',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group346-zinc_tablet':'logisticsManagement-zincORS',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group346-oxytocine':'logisticsManagement-coldChainItems'},axis=1, inplace=True)\n",
        "\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Logistics.csv')\n",
        "\n",
        "            logistics_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "            logistics_df2 = logistics_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "\n",
        "             #reposition year and source\n",
        "            yr = logistics_df2.pop('year')\n",
        "            sc = logistics_df2.pop('source')\n",
        "            id = logistics_df2.pop('id')\n",
        "            logistics_df2=pd.concat([id,logistics_df2,yr,sc],axis=1)\n",
        "\n",
        "            # Upload df as xlsx to Azure\n",
        "            upload_excel(logistics_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/merged\", \"Logistics_management_pipeline.xlsx\")\n",
        "\n",
        "        # operations to be performed if the intervention input by the user is 4\n",
        "        elif 'SERVICES' in PHC_fold[i] and 'SERVICES' in SHF_fold[i]:\n",
        "            # rename all mapped SHF column names to be uniform with the PHC intervention column names\n",
        "            shf_file.rename({\n",
        "            'ggrp3-childbirth_labour-service_provision_c-zzz37-provide_care_during_labour_and_delivery':'chilhbirth_mm5-serviceprovision_mm5-Care_during_labour_and_childbirth_mm5',\n",
        "            'ggrp2-pregnancy-service_provision_b-zzz2-nutritional_counselling_and_food_demonstration':'nutrition_mm13-patient_management_mm13-nutrition_counselling_mm13',\n",
        "            'ggrp10-immunization-service_provision_h-group214-followup_planned_routine_immunization_session_being_conducted':'immunization_mm12-rew_micrplan_in_use_mm12'\n",
        "            }, axis =1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Services.csv')\n",
        "\n",
        "            services_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "            services_df2 = services_df.drop_duplicates(keep='first') #remove duplicates\n",
        "\n",
        "\n",
        "            #reposition year and source\n",
        "            yr = services_df2.pop('year')\n",
        "            sc = services_df2.pop('source')\n",
        "            id = services_df2.pop('id')\n",
        "            services_df2=pd.concat([id,services_df2,yr,sc],axis=1)\n",
        "\n",
        "\n",
        "                 #rename columns with truncated names\n",
        "            services_df3=services_df2.rename({\"ggrp8-hiv_preventn_treatmnt-adolescent_friendly_and_youth_wellness_services-group153-do_clients_receive_sexually_transmitted_infection_screening\":\"grp8-hiv_prvntn_trtmnt-adlscnt_frndly_&_youth_welnes_servics-grp153-do_clients_recive_sxualy_trnsmitd_infctn_screning\",\n",
        "\n",
        "            \"ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art\":\"grp8-hiv_prvntn_treatmnt-pdiatrc_art-prt-are_al_cnfrmed_hiv_infctd_chldrn_wit_tretmnt_failre_swtchd_to_2nd_line_art\",\n",
        "\n",
        "            \"ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care\":\"grp8-hiv_prevntn_treatmnt-prevntn_of_mthr_to_chld_trnsmssn-ptt-do_al_prgnnt_womn_recive_cnseling_&_tstng_durng_antnatl_cre\",\n",
        "\n",
        "            \"ggrp3-childbirth_labour-service_provision_c-zzz37-manage_obstetric_complications_in_childbirth_and_immediate_post_partum_period\":\"grp3-chldbrth_labr-srvce_prvisn_c-z37-mnage_obstetrc_cmplicatns_in_chldbrth_&_imediate_pst_partm_perod\",\n",
        "\n",
        "            \"ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-group165-are_all_heis_provided_with_arv_prophylaxis_at_birth\":\"grp8-hiv_prvntn_treatmnt-prvntn_of_mothr_to_chld_trnsmisn-grp165-are_al_his_prvidd_wth_arv_prphylxis_at_brth\",\n",
        "\n",
        "            \"ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_prevention_and_management_of_hiv_sexually_transmitted_infection\":\"grp1-adlscnt_prepregnancy-servce_prvisn_a-grp62-cary_out_prevntn_&_managmnt_of_hiv_sxualy_trnsmitd_infctn\",\n",
        "\n",
        "            \"ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_appropriate_management_of_infertile_couple_including_hiv_discordant_couples\":\"grp1-adolscnt_preprgnncy-service_prvisn_a-grp62-cary_out_apropriate_mnagmnt_of_infrtile_couple_incldng_hiv_dscrdnt_coupls\",\n",
        "\n",
        "            \"ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art.1\":\"grp8-hiv_prevntn_treatmnt-pediatrc_art-prt-are_all_cnfirmd_hiv_infctd_childrn_with_treatmnt_failre_swtchd_to_2nd_lne_art1\",\n",
        "\n",
        "            \"ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care.1\":\"grp8-hiv_prevntn_trtmnt-prventn_of_mothr_to_child_trnsmisn-pt-do_al_prgnnt_women_recive_cnseling_&_tstng_drng_antnatl_cre1\"}, axis=1)\n",
        "\n",
        "\n",
        "            # Upload df as xlsx to Azure\n",
        "            upload_excel(services_df3, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/merged\", \"ISS_Service.xlsx\")\n",
        "\n",
        "        # operations to be performed if the intervention input by the user is 6\n",
        "        elif 'STAFF AVAILABILITY' in PHC_fold[i] and 'STAFF AVAILABILITY' in SHF_fold[i]:\n",
        "            # rename all mapped SHF column names to be uniform with the corresponding PHC column names\n",
        "            shf_file.rename({\n",
        "              'grp1-human_resources-staff_availability-group32-followup_how_many_registered_midwives':'grp1-humanResources-staffAvailability-no_registered_midwives_nurses',\n",
        "              'grp1-human_resources-staff_availability-group36-followup_how_many_laboratory_technicians':'grp1-humanResources-staffAvailability-no_labtech',\n",
        "              'grp1-human_resources-staff_availability-group35-followup_how_many_pharmacy_technicians':'grp1-humanResources-staffAvailability-no_pharmtech',\n",
        "              'grp1-human_resources-staff_availability-group39-followup_how_many_community_health_officers':'grp1-humanResources-staffAvailability-no_CHO',\n",
        "              'grp1-human_resources-staff_availability-group31-followup_how_many_medical_officers':'grp1-humanResources-staffAvailability-no_medical_officers'\n",
        "            }, axis =1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Staff_Availability.csv')\n",
        "\n",
        "            staffav_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "            staffav_df2 = staffav_df.drop_duplicates(keep='first') #remove duplicates\n",
        "\n",
        "            #reposition year and source\n",
        "            yr = staffav_df2.pop('year')\n",
        "            sc = staffav_df2.pop('source')\n",
        "            id = staffav_df2.pop('id')\n",
        "            staffav_df2=pd.concat([id,staffav_df2,yr,sc],axis=1)\n",
        "\n",
        "\n",
        "            # Upload df as xlsx to Azure\n",
        "            upload_excel(staffav_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/merged\", \"ISS_staff_availability.xlsx\")\n",
        "\n",
        "        # operations to be performed if the intervention input by the user is 6\n",
        "        elif 'STAFF TRAINING' in PHC_fold[i] and 'STAFF TRAINING' in SHF_fold[i]:\n",
        "            # rename all mapped SHF column names of the intervention to be uniform with the corresponding PHC column names\n",
        "            shf_file.rename({\n",
        "              'grp1-human_resources-staff_training-group57-staff_trained_on_malaria_management':'grp1-humanResources-staffTraining-num_trained_malaria',\n",
        "              'grp1-human_resources-staff_training-group53-staff_trained_on_youth_friendly_health_services':'grp1-humanResources-staffTraining-num_trained_youthfriendly_centre',\n",
        "              'grp1-human_resources-staff_training-group52-staff_trained_on_fp_clms_and_ctu_':'grp1-humanResources-staffTraining-num_trained_famplanning',\n",
        "              'grp1-human_resources-staff_training-group50-staff_trained_on_hiv_aids_management':'grp1-humanResources-staffTraining-num_trained_HIV',\n",
        "              'grp1-human_resources-staff_training-group49-staff_trained_on_integrated_management_of_childhood_illness':'grp1-humanResources-staffTraining-num_trained_imci',\n",
        "              'grp1-human_resources-staff_training-group54-staff_trained_on_using_nhmis_version_19_tools':'grp1-humanResources-staffTraining-num_trained_hmis_tool'\n",
        "            }, axis = 1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Staff_Trained.csv')\n",
        "\n",
        "            staff_train_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "            staff_train_df2 = staff_train_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "            #reposition year and source\n",
        "            yr = staff_train_df2.pop('year')\n",
        "            sc = staff_train_df2.pop('source')\n",
        "            id = staff_train_df2.pop('id')\n",
        "            staff_train_df2=pd.concat([id,staff_train_df2,yr,sc],axis=1)\n",
        "\n",
        "            # Upload df as xlsx to Azure\n",
        "            upload_excel(staff_train_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/merged\", \"staff_training_pipeline.xlsx\")\n",
        "\n",
        "\n",
        "\n",
        "# In[34]:\n",
        "\n",
        "\n",
        "appending()\n",
        "\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "\n",
        "# This function checks if files exist. If it exists, it appends. If it doesnt, it uploads the file.\n",
        "\n",
        "def check_and_upload_file(df, outputPath, filename):\n",
        "  blob_client = blob_service_client.get_blob_client(container=outputPath, blob=filename)\n",
        "\n",
        "    #reposition id, year and source\n",
        "  yr = df.pop('year')\n",
        "  sc = df.pop('source')\n",
        "  id = df.pop('id')\n",
        "  df=pd.concat([id,df,yr,sc],axis=1)\n",
        "\n",
        "\n",
        "  if not blob_client.exists():\n",
        "    # If the file doesn't exist, create a new one\n",
        "    dataframe_Buffer = io.BytesIO()\n",
        "    df.to_excel(dataframe_Buffer, index=False)\n",
        "    df_value = dataframe_Buffer.getvalue()\n",
        "    blob_client.upload_blob(df_value, overwrite=True)\n",
        "    print(\"File doesn't exist and has been uploaded\")\n",
        "\n",
        "  else:\n",
        "    # If the file exists, append the data to the existing file\n",
        "    stream = blob_client.download_blob().content_as_bytes()\n",
        "    df2 = pd.read_excel(io.BytesIO(stream))\n",
        "    df2 = df2.reset_index(drop=True)\n",
        "\n",
        "    # df2 = df2.append(df)\n",
        "    # df3 = df2.drop_duplicates(keep='first') # drop duplicates\n",
        "\n",
        "    # Use pd.concat instead of df.append as df.append is deprecated\n",
        "    df3 = pd.concat([df2, df]).drop_duplicates(keep='first')\n",
        "\n",
        "\n",
        "    # Upload excel file\n",
        "    dataframe_Buffer = io.BytesIO()\n",
        "    df3.to_excel(dataframe_Buffer, index=False)\n",
        "    df3_value = dataframe_Buffer.getvalue()\n",
        "    blob_client.upload_blob(df3_value, overwrite=True)\n",
        "    print(\"File exists and has been appended\")\n",
        "\n",
        "\n",
        "# In[42]:\n",
        "\n",
        "\n",
        "def filter_each_intervention():\n",
        "  import pandas as pd\n",
        "  path = sorted_blob_list[0].name\n",
        "#   path = \"PHC or SHF\"   #For Local Testing\n",
        "  if 'PHC' in path:\n",
        "    # List the blobs with .xlsx extension in the PHC folder\n",
        "    PHC_fold = sorted([blob.name for blob in blob_service_client.get_container_client(container_name).list_blobs(name_starts_with='Output v4-Finalized Orignial/ISS Pipelines/Output/PHC/') if blob.name.endswith('.xlsx')])\n",
        "\n",
        "\n",
        "    all_phc_num = ['grp1-humanResources-staffTraining-trained_HIV',\n",
        "              'grp1-humanResources-staffTraining-trained_malaria',\n",
        "              'grp1-humanResources-staffTraining-trained_Tuberculosis',\n",
        "              'grp1-humanResources-staffTraining-trained_famplanning',\n",
        "              'grp1-humanResources-staffTraining-trained_youthfriendly_centre',\n",
        "              'grp1-humanResources-staffTraining-trained_hmis_tool',\n",
        "              'grp1-humanResources-staffTraining-trained_intergrated_mnch',\n",
        "              'grp1-humanResources-staffTraining-trained_ganc',\n",
        "              'grp1-humanResources-staffTraining-trained_genderbased_violence',\n",
        "              'grp1-humanResources-staffTraining-trained_inventory_management',\n",
        "              'grp1-humanResources-staffAvailability-no_registered_midwives_nurses',\n",
        "              'grp1-humanResources-staffAvailability-no_jchew',\n",
        "              'grp1-humanResources-staffAvailability-no_labtech',\n",
        "              'grp1-humanResources-staffAvailability-no_pharmtech',\n",
        "              'grp1-humanResources-staffAvailability-no_chew',\n",
        "              'grp1-humanResources-staffAvailability-no_CHO',\n",
        "              'grp1-humanResources-staffAvailability-no_medical_officers',\n",
        "              'grp1-humanResources-staffAvailability-num_Community_Volunteers_are_available'\n",
        "              ]\n",
        "\n",
        "    for filename in PHC_fold:\n",
        "      phc_num = ['id','year', 'source']\n",
        "      phc_binary = ['id','year', 'source']\n",
        "\n",
        "      phc_blob_client = blob_service_client.get_blob_client(container_name, filename)\n",
        "      stream = phc_blob_client.download_blob().content_as_bytes()\n",
        "      df = pd.read_excel(io.BytesIO(stream))\n",
        "\n",
        "      # Check if any column names match all_phc_num\n",
        "      matching_columns = [col for col in df.columns if col in all_phc_num]\n",
        "      non_matching_columns = [col for col in df.columns if col not in all_phc_num]\n",
        "\n",
        "      phc_num = phc_num + matching_columns\n",
        "      phc_num = list(set(phc_num))\n",
        "\n",
        "      phc_binary = phc_binary + non_matching_columns\n",
        "      phc_binary = list(set(phc_binary))\n",
        "\n",
        "      if len(phc_num)>3:\n",
        "        df_num = df[phc_num]\n",
        "        df_num.reset_index(drop=True, inplace=True)\n",
        "        df_num.to_excel('h_' + filename.split('/')[-1])\n",
        "        check_and_upload_file (df_num , \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_PHC\", 'h_' + filename.split('/')[-1])\n",
        "\n",
        "      if len(phc_binary)>3:\n",
        "        df_bin = df[phc_binary]\n",
        "        df_bin.reset_index(drop=True, inplace=True)\n",
        "        check_and_upload_file (df_bin , \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_PHC\", 'd_' + filename.split('/')[-1])\n",
        "        # df_bin.to_excel('d_' + filename.split('/')[-1])\n",
        "\n",
        "\n",
        "# Filter for SHF Data\n",
        "\n",
        "  if 'SHF' in path:\n",
        "    # List the blobs with .xlsx extension in the SHF folder\n",
        "    SHF_fold = sorted([blob.name for blob in blob_service_client.get_container_client(container_name).list_blobs(name_starts_with='Output v4-Finalized Orignial/ISS Pipelines/Output/SHF/') if blob.name.endswith('.xlsx')])\n",
        "\n",
        "\n",
        "    all_shf_num = ['grp1-human_resources-staff_availability-group32-followup_how_many_registered_midwives',\n",
        "              'grp1-human_resources-staff_availability-group33-followup_how_many_registered_general_nurses',\n",
        "              'grp1-human_resources-staff_availability-group36-followup_how_many_laboratory_technicians',\n",
        "              'grp1-human_resources-staff_availability-group35-followup_how_many_pharmacy_technicians',\n",
        "              'grp1-human_resources-staff_availability-group39-followup_how_many_community_health_officers',\n",
        "              'grp1-human_resources-staff_availability-group31-followup_how_many_medical_officers'\n",
        "              ]\n",
        "\n",
        "    for filename in SHF_fold:\n",
        "      shf_num = ['id','year', 'source']\n",
        "      shf_binary = ['id','year', 'source']\n",
        "\n",
        "      shf_blob_client = blob_service_client.get_blob_client(container_name, filename)\n",
        "      stream = shf_blob_client.download_blob().content_as_bytes()\n",
        "      df = pd.read_excel(io.BytesIO(stream))\n",
        "\n",
        "      # Check if any column names match all_shf_num\n",
        "      matching_columns = [col for col in df.columns if col in all_shf_num]\n",
        "\n",
        "      # Columns that dont match all_shf_num\n",
        "      non_matching_columns = [col for col in df.columns if col not in all_shf_num]\n",
        "\n",
        "\n",
        "      shf_num = shf_num + matching_columns\n",
        "      shf_num = list(set(shf_num))  # make list unique\n",
        "\n",
        "      shf_binary = shf_binary + non_matching_columns\n",
        "      shf_binary = list(set(shf_binary)) # make list unique\n",
        "\n",
        "      if len(shf_num)>3:\n",
        "        df_num = df[shf_num]\n",
        "        df_num.reset_index(drop=True, inplace=True)\n",
        "        df_num.to_excel('h_' + filename.split('/')[-1])\n",
        "        check_and_upload_file (df_num , \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_SHF\", 'h_' + filename.split('/')[-1])\n",
        "\n",
        "      if len(shf_binary)>3:\n",
        "        df_bin = df[shf_binary]\n",
        "        df_bin.reset_index(drop=True, inplace=True)\n",
        "        check_and_upload_file (df_bin , \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_SHF\", 'd_' + filename.split('/')[-1])\n",
        "\n",
        "\n",
        "\n",
        "# In[43]:\n",
        "\n",
        "\n",
        "filter_each_intervention()\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[44]:\n",
        "\n",
        "\n",
        "def merge_filtered_interventions():\n",
        "  # List the blobs with .xlsx extension in the PHC folder\n",
        "    PHC_fold = sorted([blob.name for blob in blob_service_client.get_container_client(container_name).list_blobs(name_starts_with='Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_PHC/') if blob.name.endswith('.xlsx')])\n",
        "    # List the blobs with .xlsx extension in the SHF folder\n",
        "    SHF_fold = sorted([blob.name for blob in blob_service_client.get_container_client(container_name).list_blobs(name_starts_with='Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_SHF/') if blob.name.endswith('.xlsx')])\n",
        "\n",
        "    for i in range(len(PHC_fold)):\n",
        "\n",
        "        # Download the PHC Excel file from Azure Blob Storage\n",
        "        phc_blob_client = blob_service_client.get_blob_client(container_name, PHC_fold[i])\n",
        "        stream = phc_blob_client.download_blob().content_as_bytes()\n",
        "        phc_file = pd.read_excel(io.BytesIO(stream))\n",
        "\n",
        "        # Download the SHF file from Azure Blob Storage\n",
        "        shf_blob_client = blob_service_client.get_blob_client(container_name, SHF_fold[i])\n",
        "        stream = shf_blob_client.download_blob().content_as_bytes()\n",
        "        shf_file = pd.read_excel(io.BytesIO(stream))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if \"d_EQUIPMENT.xlsx\" in PHC_fold[i].replace(\"PHC \", \"\").split(\"/\")[-1] and \"d_EQUIPMENT.xlsx\" in SHF_fold[i].replace(\"SHF \", \"\").split(\"/\")[-1]:\n",
        "          shf_file.rename({'ggrp3-childbirth_labour-equipment_and_supplies_c-zzz55-delivery_packs':'chilhbirth_mm5-equipment_mm5-delivery_bed_mm5',\n",
        "                    'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-group68-is_oxygen_available':'chilhbirth_mm5-equipment_mm5-Oxygen_mm5',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group83-oxygen':'chilhbirth_mm5-equipment_mm5-Ambu_bag_mask_mm5',\n",
        "                    'ggrp2-pregnancy-equipment_and_supplies_b-group75-sphygmomanometer':'pregnancy_mm4-equipment_mm4-Sphygmanometer_mm4',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-zzz55-sphygmomanometer':'chilhbirth_mm5-equipment_mm5-Sphygmomanometer_and_Stethoscope_mm5',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group84-adult_stethoscopes_and_fetoscopes':'pregnancy_mm4-equipment_mm4-Fetal_and_Adult_Stethoscope_mm4',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group85-clinical_thermometers':'chilhbirth_mm5-equipment_mm5-thermometer_mm5',\n",
        "                    'ggrp5-newborn_care-equipment_and_supplies_e-zzz133-facility_have_thermometers':'newborn_care_mm7-equipment_mm7-Low_reading_thermomether_mm7',\n",
        "                    'ggrp16-laboratoryServices-facility_safety-group260-bleach_and_other_disinfectants':'laboratoryServices-m102-bleachAndDisinfectants',\n",
        "                    'ggrp2-pregnancy-equipment_and_supplies_b-zzz20-digital_blood_pressure_device_traffic_light_':'pregnancy_mm4-equipment_mm4-Digital_Blood_Pressure_Device_mm4',\n",
        "                    'ggrp3-childbirth_labour-equipment_and_supplies_c-group85-weighing_scales':'childhealth_mm8-equipment_mm8-Infant_Weighing_Scales_mm8',\n",
        "                    'ggrp2-pregnancy-equipment_and_supplies_b-zzz20-weighing_scale':'pregnancy_mm4-equipment_mm4-Weighing_Scale_mm4'}, axis=1, inplace = True)\n",
        "\n",
        "\n",
        "          equipment_df = pd.concat([phc_file, shf_file], axis=0, ignore_index=True)\n",
        "          equipment_df2 = equipment_df.drop_duplicates(keep='first') # remove duplicates\n",
        "          yr = equipment_df2.pop('year')\n",
        "          sc = equipment_df2.pop('source')\n",
        "          id = equipment_df2.pop('id')\n",
        "          equipment_df2=pd.concat([id,equipment_df2,yr,sc],axis=1)\n",
        "          # Upload df as xlsx to Azure\n",
        "          upload_excel(equipment_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_merged\", \"d_ISS_Equipment.xlsx\")\n",
        "\n",
        "        # ............\n",
        "\n",
        "\n",
        "        elif \"d_INFRASTRUCTURE.xlsx\" in PHC_fold[i].replace(\"PHC \", \"\").split(\"/\")[-1] and \"d_INFRASTRUCTURE.xlsx\" in SHF_fold[i].replace(\"SHF \", \"\").split(\"/\")[-1]:\n",
        "          shf_file.rename({'grp1-external_env_and_infrastructure:group8-functional_source_of_power_supply_to_the_facility':'grp1-ExternalEnvironmentPhysicalInfrastructure-functional_source_of_power_supply_to_this_facility',\n",
        "            'grp1-external_env_and_infrastructure-group8-facility_fenced':'grp1-ExternalEnvironmentPhysicalInfrastructure-health_facility_fenced',\n",
        "\n",
        "            'grp1-external_env_and_infrastructure-ff17-accessible_road_to_the_facility':'grp1-ExternalEnvironmentPhysicalInfrastructure-Accessible_road_to_the_facility',\n",
        "            'grp1-external_env_and_infrastructure-group6-facilitys_sewage_disposal_system_adequate':'grp1-ExternalEnvironmentPhysicalInfrastructure-sewage_disposal_system_adequate',\n",
        "            'grp1-external_env_and_infrastructure-group5-facility_have_potable_water':'grp1-ExternalEnvironmentPhysicalInfrastructure-potable_water_available',\n",
        "            'grp1-external_env_and_infrastructure-group6-facility_have_a_sharp_disposal_system_in_place':'grp1-ExternalEnvironmentPhysicalInfrastructure-sharp_disposal_system',\n",
        "            'grp1-external_env_and_infrastructure-group5-facility_well_ventilated':'grp1-ExternalEnvironmentPhysicalInfrastructure-facility_well_ventilated',\n",
        "            'grp1-external_env_and_infrastructure-group5-roof_intact_with_no_leaking_part':'grp1-ExternalEnvironmentPhysicalInfrastructure-roof_intact_with_no_leaking',\n",
        "            'grp1-external_env_and_infrastructure-ff17-walls_free_of_cracks_and_crevices':'grp1-ExternalEnvironmentPhysicalInfrastructure-walls_free_of_cracks',\n",
        "            'grp1-external_env_and_infrastructure-group7-facility_carry_out_quarterly_pest_control_activities':'grp1-ExternalEnvironmentPhysicalInfrastructure-quaterly_rodent_and_pest_control',\n",
        "            'grp1-external_env_and_infrastructure-group8-functional_source_of_power_supply_to_the_facility':'grp1-ExternalEnvironmentPhysicalInfrastructure-functional_source_of_power_supply_to_this_facility',\n",
        "            'grp1-external_env_and_infrastructure-group6-facilitys_waste_disposal_system_adequate':'grp1-ExternalEnvironmentPhysicalInfrastructure-waste_disposal_system_adequate',\n",
        "            'grp1-external_env_and_infrastructure-ff17-facility_environment_generally_neat_and_tidy': 'grp1-ExternalEnvironmentPhysicalInfrastructure-environment_generally_tidy'\n",
        "            }, axis=1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file], axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Infrastructure.csv')\n",
        "\n",
        "          infra_df = pd.concat([phc_file,shf_file], axis=0, ignore_index=True)\n",
        "          infra_df2 = infra_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "\n",
        "          #reposition year and source\n",
        "          yr = infra_df2.pop('year')\n",
        "          sc = infra_df2.pop('source')\n",
        "          id = infra_df2.pop('id')\n",
        "          infra_df2=pd.concat([id,infra_df2,yr,sc],axis=1)\n",
        "\n",
        "          # Upload df as xlsx to Azure\n",
        "          upload_excel(infra_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_merged\", \"d_infrastructure_pipeline.xlsx\")\n",
        "\n",
        "\n",
        "        elif \"d_LOGISTICS.xlsx\" in PHC_fold[i].replace(\"PHC \", \"\").split(\"/\")[-1] and \"d_LOGISTICS.xlsx\" in SHF_fold[i].replace(\"SHF \", \"\").split(\"/\")[-1]:\n",
        "          shf_file.rename({\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group345-albendazole':'logisticsManagement-albendazole',\n",
        "            'ggrp11-nutrition-medicines_and_other_health_technologies_i-group239-albendezole_mebendazole':'logisticsManagement-mebendazole',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group344-act':'logisticsManagement-acts',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group345-dispersible_amoxicillin_tablets':'logisticsManagement-dispersible',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group348-oral_pills':'logisticsManagement-contraceptive',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group339-iron_and_folic_acid_tablet':'logisticsManagement-folic',\n",
        "            'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-ff230-are_male_condoms_available':'logisticsManagement-condomMale',\n",
        "            'ggrp1-adolescent_prepregnancy-equipment_and_supplies_a-ff230-are_female_condoms_available':'logisticsManagement-condomFemale',\n",
        "            'ggrp6-childhealth-medicines_and_other_health_technologies_f-group120-facility_have_vitamin_a':'logisticsManagement-vitaminA',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group341-tetanus_toxoid':'logisticsManagement-tetanus',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group346-zinc_tablet':'logisticsManagement-zincORS',\n",
        "            'ggrp18-logistics_management-data_verification-medicine_supplies_equipment_l-group346-oxytocine':'logisticsManagement-coldChainItems'},axis=1, inplace=True)\n",
        "\n",
        "\n",
        "          # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "          # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Logistics.csv')\n",
        "\n",
        "          logistics_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "          logistics_df2 = logistics_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "\n",
        "            #reposition year and source\n",
        "          yr = logistics_df2.pop('year')\n",
        "          sc = logistics_df2.pop('source')\n",
        "          id = logistics_df2.pop('id')\n",
        "          logistics_df2=pd.concat([id,logistics_df2,yr,sc],axis=1)\n",
        "\n",
        "          # Upload df as xlsx to Azure\n",
        "          upload_excel(logistics_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_merged\", \"d_Logistics_management_pipeline.xlsx\")\n",
        "\n",
        "\n",
        "        elif \"d_SERVICES.xlsx\" in PHC_fold[i].replace(\"PHC \", \"\").split(\"/\")[-1] and \"d_SERVICES.xlsx\" in SHF_fold[i].replace(\"SHF \", \"\").split(\"/\")[-1]:\n",
        "          shf_file.rename({\n",
        "            'ggrp3-childbirth_labour-service_provision_c-zzz37-provide_care_during_labour_and_delivery':'chilhbirth_mm5-serviceprovision_mm5-Care_during_labour_and_childbirth_mm5',\n",
        "            'ggrp2-pregnancy-service_provision_b-zzz2-nutritional_counselling_and_food_demonstration':'nutrition_mm13-patient_management_mm13-nutrition_counselling_mm13',\n",
        "            'ggrp10-immunization-service_provision_h-group214-followup_planned_routine_immunization_session_being_conducted':'immunization_mm12-rew_micrplan_in_use_mm12'\n",
        "            }, axis =1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Services.csv')\n",
        "\n",
        "          services_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "          services_df2 = services_df.drop_duplicates(keep='first') #remove duplicates\n",
        "\n",
        "\n",
        "          #reposition year and source\n",
        "          yr = services_df2.pop('year')\n",
        "          sc = services_df2.pop('source')\n",
        "          id = services_df2.pop('id')\n",
        "          services_df2=pd.concat([id,services_df2,yr,sc],axis=1)\n",
        "\n",
        "\n",
        "                #rename columns with truncated names\n",
        "          services_df3=services_df2.rename({\"ggrp8-hiv_preventn_treatmnt-adolescent_friendly_and_youth_wellness_services-group153-do_clients_receive_sexually_transmitted_infection_screening\":\"grp8-hiv_prvntn_trtmnt-adlscnt_frndly_&_youth_welnes_servics-grp153-do_clients_recive_sxualy_trnsmitd_infctn_screning\",\n",
        "\n",
        "          \"ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art\":\"grp8-hiv_prvntn_treatmnt-pdiatrc_art-prt-are_al_cnfrmed_hiv_infctd_chldrn_wit_tretmnt_failre_swtchd_to_2nd_line_art\",\n",
        "\n",
        "          \"ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care\":\"grp8-hiv_prevntn_treatmnt-prevntn_of_mthr_to_chld_trnsmssn-ptt-do_al_prgnnt_womn_recive_cnseling_&_tstng_durng_antnatl_cre\",\n",
        "\n",
        "          \"ggrp3-childbirth_labour-service_provision_c-zzz37-manage_obstetric_complications_in_childbirth_and_immediate_post_partum_period\":\"grp3-chldbrth_labr-srvce_prvisn_c-z37-mnage_obstetrc_cmplicatns_in_chldbrth_&_imediate_pst_partm_perod\",\n",
        "\n",
        "          \"ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-group165-are_all_heis_provided_with_arv_prophylaxis_at_birth\":\"grp8-hiv_prvntn_treatmnt-prvntn_of_mothr_to_chld_trnsmisn-grp165-are_al_his_prvidd_wth_arv_prphylxis_at_brth\",\n",
        "\n",
        "          \"ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_prevention_and_management_of_hiv_sexually_transmitted_infection\":\"grp1-adlscnt_prepregnancy-servce_prvisn_a-grp62-cary_out_prevntn_&_managmnt_of_hiv_sxualy_trnsmitd_infctn\",\n",
        "\n",
        "          \"ggrp1-adolescent_prepregnancy-service_provision_a-group62-carry_out_appropriate_management_of_infertile_couple_including_hiv_discordant_couples\":\"grp1-adolscnt_preprgnncy-service_prvisn_a-grp62-cary_out_apropriate_mnagmnt_of_infrtile_couple_incldng_hiv_dscrdnt_coupls\",\n",
        "\n",
        "          \"ggrp8-hiv_preventn_treatmnt-pediatric_art-part-are_all_confirmed_hiv_infected_children_with_treatment_failure_switched_to_2nd_line_art.1\":\"grp8-hiv_prevntn_treatmnt-pediatrc_art-prt-are_all_cnfirmd_hiv_infctd_childrn_with_treatmnt_failre_swtchd_to_2nd_lne_art1\",\n",
        "\n",
        "          \"ggrp8-hiv_preventn_treatmnt-prevention_of_mother_to_child_transmission-ptt-do_all_pregnant_women_receive_counselling_and_testing_during_antenatal_care.1\":\"grp8-hiv_prevntn_trtmnt-prventn_of_mothr_to_child_trnsmisn-pt-do_al_prgnnt_women_recive_cnseling_&_tstng_drng_antnatl_cre1\"}, axis=1)\n",
        "\n",
        "\n",
        "          # Upload df as xlsx to Azure\n",
        "          upload_excel(services_df3, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_merged\", \"d_ISS_Service.xlsx\")\n",
        "\n",
        "\n",
        "\n",
        "        elif \"d_STAFF TRAINING.xlsx\" in PHC_fold[i].replace(\"PHC \", \"\").split(\"/\")[-1] and \"d_STAFF TRAINING.xlsx\" in SHF_fold[i].replace(\"SHF \", \"\").split(\"/\")[-1]:\n",
        "          shf_file.rename({\n",
        "              'grp1-human_resources-staff_training-group57-staff_trained_on_malaria_management':'grp1-humanResources-staffTraining-num_trained_malaria',\n",
        "              'grp1-human_resources-staff_training-group53-staff_trained_on_youth_friendly_health_services':'grp1-humanResources-staffTraining-num_trained_youthfriendly_centre',\n",
        "              'grp1-human_resources-staff_training-group52-staff_trained_on_fp_clms_and_ctu_':'grp1-humanResources-staffTraining-num_trained_famplanning',\n",
        "              'grp1-human_resources-staff_training-group50-staff_trained_on_hiv_aids_management':'grp1-humanResources-staffTraining-num_trained_HIV',\n",
        "              'grp1-human_resources-staff_training-group49-staff_trained_on_integrated_management_of_childhood_illness':'grp1-humanResources-staffTraining-num_trained_imci',\n",
        "              'grp1-human_resources-staff_training-group54-staff_trained_on_using_nhmis_version_19_tools':'grp1-humanResources-staffTraining-num_trained_hmis_tool'\n",
        "            }, axis = 1, inplace = True)\n",
        "\n",
        "          # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "          # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Staff_Trained.csv')\n",
        "\n",
        "          staff_train_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "          staff_train_df2 = staff_train_df.drop_duplicates(keep='first') # remove duplicates\n",
        "\n",
        "          #reposition year and source\n",
        "          yr = staff_train_df2.pop('year')\n",
        "          sc = staff_train_df2.pop('source')\n",
        "          id = staff_train_df2.pop('id')\n",
        "          staff_train_df2=pd.concat([id,staff_train_df2,yr,sc],axis=1)\n",
        "\n",
        "          # Upload df as xlsx to Azure\n",
        "          upload_excel(staff_train_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_merged\", \"d_staff_training_pipeline.xlsx\")\n",
        "\n",
        "\n",
        "        elif \"h_STAFF AVAILABILITY.xlsx\" in PHC_fold[i].replace(\"PHC \", \"\").split(\"/\")[-1] and \"h_STAFF AVAILABILITY.xlsx\" in SHF_fold[i].replace(\"SHF \", \"\").split(\"/\")[-1]:\n",
        "          shf_file.rename({\n",
        "              'grp1-human_resources-staff_availability-group32-followup_how_many_registered_midwives':'grp1-humanResources-staffAvailability-no_registered_midwives_nurses',\n",
        "              'grp1-human_resources-staff_availability-group36-followup_how_many_laboratory_technicians':'grp1-humanResources-staffAvailability-no_labtech',\n",
        "              'grp1-human_resources-staff_availability-group35-followup_how_many_pharmacy_technicians':'grp1-humanResources-staffAvailability-no_pharmtech',\n",
        "              'grp1-human_resources-staff_availability-group39-followup_how_many_community_health_officers':'grp1-humanResources-staffAvailability-no_CHO',\n",
        "              'grp1-human_resources-staff_availability-group31-followup_how_many_medical_officers':'grp1-humanResources-staffAvailability-no_medical_officers'\n",
        "            }, axis =1, inplace = True)\n",
        "\n",
        "            # concatenate / append both PHC and SHF files and output as a single CSV file\n",
        "            # pd.concat([phc_file,shf_file],axis=0, ignore_index=True).to_csv(f'../output/merged/Complete_Staff_Availability.csv')\n",
        "\n",
        "          staffav_df = pd.concat([phc_file,shf_file],axis=0, ignore_index=True)\n",
        "          staffav_df2 = staffav_df.drop_duplicates(keep='first') #remove duplicates\n",
        "\n",
        "          #reposition year and source\n",
        "          yr = staffav_df2.pop('year')\n",
        "          sc = staffav_df2.pop('source')\n",
        "          id = staffav_df2.pop('id')\n",
        "          staffav_df2=pd.concat([id,staffav_df2,yr,sc],axis=1)\n",
        "\n",
        "\n",
        "          # Upload df as xlsx to Azure\n",
        "          upload_excel(staffav_df2, \"hefaanalytics/Output v4-Finalized Orignial/ISS Pipelines/Output/Filtered_merged\", \"h_ISS_staff_availability.xlsx\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[45]:\n",
        "\n",
        "\n",
        "merge_filtered_interventions()\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3OXwRHcOL2p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}